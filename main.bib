@ARTICLE{llm_application_se,
	author={Ozkaya, Ipek},
	journal={IEEE Software}, 
	title={Application of Large Language Models to Software Engineering Tasks: Opportunities, Risks, and Implications}, 
	year={2023},
	volume={40},
	number={3},
	pages={4-8},
	keywords={},
	doi={10.1109/MS.2023.3248401}}

@article{roziere2023code,
	title={Code llama: Open foundation models for code},
	author={Roziere, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and others},
	journal={arXiv preprint arXiv:2308.12950},
	year={2023}
}

@article{hui2024qwen2,
	title={Qwen2. 5-coder technical report},
	author={Hui, Binyuan and Yang, Jian and Cui, Zeyu and Yang, Jiaxi and Liu, Dayiheng and Zhang, Lei and Liu, Tianyu and Zhang, Jiajun and Yu, Bowen and Lu, Keming and others},
	journal={arXiv preprint arXiv:2409.12186},
	year={2024}
}

@misc{xia2024leaderboardrankingcoding,
	title={Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval: Evolving Coding Benchmarks via LLM}, 
	author={Chunqiu Steven Xia and Yinlin Deng and Lingming Zhang},
	year={2024},
	eprint={2403.19114},
	archivePrefix={arXiv},
	primaryClass={cs.SE},
	url={https://arxiv.org/abs/2403.19114}, 
}

@article{satvaty2024undesirable,
	title={Undesirable memorization in large language models: A survey},
	author={Satvaty, Ali and Verberne, Suzan and Turkmen, Fatih},
	journal={arXiv preprint arXiv:2410.02650},
	year={2024}
}