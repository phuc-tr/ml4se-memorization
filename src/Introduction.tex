% Introduce to LLMs
% - Their advacement and how they are performing on SE benchmark. Mention code generation as one of the SE task.
% - Raise the research question.
Large language models (LLMs) have emerged as powerful tools in software engineering, offering substantial benefits to a multitude of programming tasks \cite{llm_application_se}. They can achieve state-of-the-art performance on several code benchmarks, demonstrating remarkable proficiency in areas like code generation, completion, and translation. \cite{roziere2023code}, \cite{hui2024qwen2}. 
%We've mentioned 2 code models here, should we stick to code models? Will this affect our model choice at all?
However, these advancements raise a fundamental question: Do LLMs truly generalize to new programming problems, or are they merely recalling memorized data that was seen in the training process? 

Prompting LLMs with queries in datasets that has been seen in the training process is considered a case of data contamination or leakage \cite{benchmark_cheater}. Memorization happens when the data was seen repeatedly in the training process that the LLMs can generate it consistently \cite{emergent_memo} \cite{bordt2024elephants}.
Recent research on memorization on LLMs were performed on the assumption that a dataset has been seen in the training process <cite>. They further unveil the effect of memorization by comparing the similarities between LLMs output and the training data <cite>. Input data mutation were also investigated to understand the <<<something here>>>. However, the study of how LLMs memorize code translation tasks is yet to be discussed.


% Introduce to the study of LLMs memorization in general and in software engineer task.
% - Recent research on LLMs memorization and their limitation.
% - Conclude that research on code-code is limited.

Recent research measure memorization by ... <cite>. However, this assume access to training data, or access to the model... However, the study of undesired memorization of LLMs in code translation task is yet to be investigated.

Input data mutation ... where the input code is rewritten 

% Our work
% - What will we do in this paper.
% - Briefly mention the result
In this paper, we measure the degree of memorization of LLMs in code translation tasks and study it's effect on the performance of the LLMs when there's no access to training data.

% Semantic Equivalence: Unlike general code generation (where correctness is measured by passing tests), code translation requires preserving the exact functional semantics while changing the syntax and structure. Memorization might help with syntax but fail on subtle functional differences.

% Token-Level vs. Functional Memorization: Most prior memorization work in code focused on verbatim token match. You should mention that code translation requires investigating functional memorizationâ€”did the model memorize the functionality of the source-target pair, not just the exact tokens?

% https://gemini.google.com/share/5dcbf06c66af
% Verbatim Memorization vs Functional Equivalence

% Our contribution
In summary, this paper makes the following contributions:
\begin{itemize}
	\item We did this
	\item We did that
	\item And we did one more thing
\end{itemize}
